{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNonCIFAR10_Sequential.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUdJ8ZKzMyUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If implemented in the same way as the other models, maximum accuracy 74% and overfitting after 15 epochs. (with data generator)\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import *\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAgbrwLuVZHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brtX-cWENgjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "def get_model(x_train,y_train,x_test,y_test):\n",
        "  \n",
        "  batch_size = 64\n",
        "  epochs = 125\n",
        "  data_augmentation = True\n",
        "  weight_decay = 1e-4\n",
        "\n",
        "  model = Sequential()                                                                                 # base model\n",
        "  model.add(Conv2D(32, kernel_size=3, strides=(1, 1), input_shape =(32,32,3), activation ='relu', padding='same', kernel_regularizer=regularizers.l2(weight_decay) ))     # as the image is in grayscale the shape is 28,28,1 (if rgb = (28,28,3))\n",
        "                                                                                                       # Conv2D is used for spatial convolution over images, 64 feature maps\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size = (2,2))) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64, (3, 3), padding='same', activation='relu',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.4))\n",
        " \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  print(\"\\n Model Summary \\n\")\n",
        "  model.summary()\n",
        "  \n",
        " \n",
        "  # initiate RMSprop optimizer\n",
        "  opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
        "  \n",
        "  if not data_augmentation:\n",
        "      print('Not using data augmentation.')\n",
        "      model.fit(x_train, y_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_data=(x_test, y_test),\n",
        "                shuffle=True)\n",
        "  else:\n",
        "      print('Using real-time data augmentation.')\n",
        "      # This will do preprocessing and realtime data augmentation:\n",
        "      datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,  # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False,  # divide each input by its std\n",
        "          zca_whitening=False,  # apply ZCA whitening\n",
        "          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          # randomly shift images horizontally (fraction of total width)\n",
        "          width_shift_range=0.1,\n",
        "          # randomly shift images vertically (fraction of total height)\n",
        "          height_shift_range=0.1,\n",
        "          shear_range=0.,  # set range for random shear\n",
        "          zoom_range=0.,  # set range for random zoom\n",
        "          channel_shift_range=0.,  # set range for random channel shifts\n",
        "          # set mode for filling points outside the input boundaries\n",
        "          fill_mode='nearest',\n",
        "          cval=0.,  # value used for fill_mode = \"constant\"\n",
        "          horizontal_flip=True,  # randomly flip images\n",
        "          vertical_flip=False,  # randomly flip images\n",
        "          # set rescaling factor (applied before any other transformation)\n",
        "          rescale=None,\n",
        "          # set function that will be applied on each input\n",
        "          preprocessing_function=None,\n",
        "          # image data format, either \"channels_first\" or \"channels_last\"\n",
        "          data_format=None,\n",
        "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "          validation_split=0.0)\n",
        "\n",
        "      # Compute quantities required for feature-wise normalization\n",
        "      # (std, mean, and principal components if ZCA whitening is applied).\n",
        "      datagen.fit(x_train)\n",
        "\n",
        "      # Fit the model on the batches generated by datagen.flow().\n",
        "      history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                       batch_size=batch_size),\\\n",
        "                          steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
        "                          verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)], workers=4)\n",
        "      \n",
        "        print(\"\\n Model Training \\n\")\n",
        " \n",
        "      plt.plot(history.history['acc'])                                                                        # summarize history for accuracy\n",
        "      plt.plot(history.history['val_acc'])\n",
        "      plt.title('\\n Model Accuracy \\n')\n",
        "      plt.ylabel('accuracy') \n",
        "      plt.xlabel('epoch')\n",
        "      plt.legend(['train', 'test'], loc='upper left')\n",
        "      plt.show()\n",
        "\n",
        "      plt.plot(history.history['loss'])                                                                       # summarize history for loss\n",
        "      plt.plot(history.history['val_loss'])\n",
        "      plt.title('\\n Model Loss \\n')\n",
        "      plt.ylabel('loss')\n",
        "      plt.xlabel('epoch')\n",
        "      plt.legend(['train', 'test'], loc='upper left')\n",
        "      plt.show()\n",
        "           \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgm6R911Oi1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model():\n",
        "  \n",
        "  # The data, split between train and test sets:\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  print('x_train shape:', x_train.shape)\n",
        "  print('x_test shape:',x_test.shape)\n",
        "  print(x_train.shape[0], 'train samples')\n",
        "  print(x_test.shape[0], 'test samples')\n",
        "  \n",
        "  # Convert class vectors to binary class matrices.\n",
        "  y_train = to_categorical(y_train, num_classes)\n",
        "  y_test = to_categorical(y_test, num_classes)\n",
        "  \n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  \n",
        "  mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "  std = np.std(x_train,axis=(0,1,2,3))\n",
        "  x_train = (x_train-mean)/(std+1e-7)\n",
        "  x_test = (x_test-mean)/(std+1e-7)\n",
        "\n",
        "  print(\"\\n Training model - \\n\")\n",
        "  model = get_model(x_train,y_train,x_test,y_test)                # Function call for training\n",
        "  y_test_pred = model.predict(x_test)                             # Testing\n",
        "  \n",
        "  print(\"\\n Some Outputs\\n\")\n",
        "  for i in range(10):                                             # Print first 10 test images with output classes \n",
        "    img = x_test[i].reshape((32,32,3))\n",
        "    plt.imshow(img, cmap=\"Greys\")\n",
        "    plt.show()\n",
        "    print(\"Target Value\",np.argmax(y_test_pred[i]))\n",
        "  \n",
        "  acc = model.evaluate(x_test,y_test,verbose=2)                   # Evaluation of model\n",
        "  print('\\n TEST LOSS: ', acc[0])\n",
        "  print('\\n TEST ACCURACY: ',acc[1])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VS3wJiAPxjb",
        "colab_type": "code",
        "outputId": "9742e5e7-9752-4e41-e088-c7d35ed7bb43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "\n",
            " Training model - \n",
            "\n",
            "\n",
            " Model Summary \n",
            "\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                11530     \n",
            "=================================================================\n",
            "Total params: 300,330\n",
            "Trainable params: 299,434\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Using real-time data augmentation.\n",
            "Epoch 1/125\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 1.8890 - acc: 0.4298 - val_loss: 1.3422 - val_acc: 0.5563\n",
            "Epoch 2/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 1.2018 - acc: 0.6017 - val_loss: 0.9578 - val_acc: 0.6888\n",
            "Epoch 3/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.9769 - acc: 0.6793 - val_loss: 0.8900 - val_acc: 0.7190\n",
            "Epoch 4/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.8954 - acc: 0.7134 - val_loss: 0.8646 - val_acc: 0.7321\n",
            "Epoch 5/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.8419 - acc: 0.7376 - val_loss: 0.7777 - val_acc: 0.7631\n",
            "Epoch 6/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.8067 - acc: 0.7521 - val_loss: 0.7320 - val_acc: 0.7805\n",
            "Epoch 7/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.7810 - acc: 0.7652 - val_loss: 0.7583 - val_acc: 0.7785\n",
            "Epoch 8/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.7586 - acc: 0.7752 - val_loss: 0.7010 - val_acc: 0.8023\n",
            "Epoch 9/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.7385 - acc: 0.7835 - val_loss: 0.6749 - val_acc: 0.8084\n",
            "Epoch 10/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.7275 - acc: 0.7909 - val_loss: 0.6615 - val_acc: 0.8191\n",
            "Epoch 11/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.7098 - acc: 0.7977 - val_loss: 0.6329 - val_acc: 0.8256\n",
            "Epoch 12/125\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.7068 - acc: 0.7980 - val_loss: 0.6798 - val_acc: 0.8129\n",
            "Epoch 13/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.6868 - acc: 0.8079 - val_loss: 0.6364 - val_acc: 0.8301\n",
            "Epoch 14/125\n",
            "781/781 [==============================] - 47s 61ms/step - loss: 0.6858 - acc: 0.8079 - val_loss: 0.6768 - val_acc: 0.8178\n",
            "Epoch 15/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6751 - acc: 0.8141 - val_loss: 0.6057 - val_acc: 0.8385\n",
            "Epoch 16/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6708 - acc: 0.8146 - val_loss: 0.6322 - val_acc: 0.8335\n",
            "Epoch 17/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.6638 - acc: 0.8178 - val_loss: 0.6197 - val_acc: 0.8349\n",
            "Epoch 18/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.6563 - acc: 0.8204 - val_loss: 0.6300 - val_acc: 0.8346\n",
            "Epoch 19/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6537 - acc: 0.8223 - val_loss: 0.6151 - val_acc: 0.8405\n",
            "Epoch 20/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6482 - acc: 0.8265 - val_loss: 0.6659 - val_acc: 0.8239\n",
            "Epoch 21/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.6433 - acc: 0.8276 - val_loss: 0.6009 - val_acc: 0.8444\n",
            "Epoch 22/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.6363 - acc: 0.8323 - val_loss: 0.5891 - val_acc: 0.8510\n",
            "Epoch 23/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.6347 - acc: 0.8322 - val_loss: 0.5698 - val_acc: 0.8568\n",
            "Epoch 24/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.6356 - acc: 0.8313 - val_loss: 0.5776 - val_acc: 0.8548\n",
            "Epoch 25/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.6317 - acc: 0.8329 - val_loss: 0.6255 - val_acc: 0.8393\n",
            "Epoch 26/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6236 - acc: 0.8358 - val_loss: 0.6125 - val_acc: 0.8449\n",
            "Epoch 27/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.6272 - acc: 0.8349 - val_loss: 0.5960 - val_acc: 0.8511\n",
            "Epoch 28/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.6212 - acc: 0.8393 - val_loss: 0.6551 - val_acc: 0.8340\n",
            "Epoch 29/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6215 - acc: 0.8390 - val_loss: 0.6441 - val_acc: 0.8378\n",
            "Epoch 30/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6229 - acc: 0.8389 - val_loss: 0.5826 - val_acc: 0.8536\n",
            "Epoch 31/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6129 - acc: 0.8430 - val_loss: 0.6268 - val_acc: 0.8424\n",
            "Epoch 32/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6163 - acc: 0.8411 - val_loss: 0.6116 - val_acc: 0.8439\n",
            "Epoch 33/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6110 - acc: 0.8429 - val_loss: 0.6232 - val_acc: 0.8470\n",
            "Epoch 34/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.6079 - acc: 0.8444 - val_loss: 0.6523 - val_acc: 0.8350\n",
            "Epoch 35/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.6087 - acc: 0.8445 - val_loss: 0.5716 - val_acc: 0.8573\n",
            "Epoch 36/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.6036 - acc: 0.8450 - val_loss: 0.6258 - val_acc: 0.8381\n",
            "Epoch 37/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.6046 - acc: 0.8460 - val_loss: 0.6079 - val_acc: 0.8496\n",
            "Epoch 38/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.6004 - acc: 0.8491 - val_loss: 0.6054 - val_acc: 0.8527\n",
            "Epoch 39/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6004 - acc: 0.8467 - val_loss: 0.6238 - val_acc: 0.8495\n",
            "Epoch 40/125\n",
            "143/781 [====>.........................] - ETA: 33s - loss: 0.5935 - acc: 0.8495"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPy2jR72eP6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}